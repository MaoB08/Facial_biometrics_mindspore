# Opciones para Dataset Grande

## âŒ Problema: Sin conexiÃ³n a internet

No se pudo descargar el dataset LFW automÃ¡ticamente porque no hay conexiÃ³n a internet disponible.

---

## âœ… Opciones disponibles:

### **OpciÃ³n 1: Descargar LFW manualmente** (Recomendado)

1. **Descargar el archivo** desde tu navegador:
   - URL: http://vis-www.cs.umass.edu/lfw/lfw.tgz
   - TamaÃ±o: ~173 MB
   - Contiene: ~13,000 imÃ¡genes de ~5,700 personas

2. **Extraer en el proyecto**:
   ```bash
   # Si descargaste a ~/Descargas/
   tar -xzf ~/Descargas/lfw.tgz -C /home/mauricio/Escritorio/Facial_biometrics_mindspore/data/
   
   # Luego ejecutar el script de preparaciÃ³n
   cd /home/mauricio/Escritorio/Facial_biometrics_mindspore
   source venv/bin/activate
   python3 scripts/prepare_data.py --organize-lfw
   ```

---

### **OpciÃ³n 2: Agregar mÃ¡s personas al dataset actual**

Puedes simplemente agregar mÃ¡s carpetas de personas a `data/train/` y `data/val/`:

```bash
data/train/
â”œâ”€â”€ bill_gates/
â”œâ”€â”€ elon_musk/
â”œâ”€â”€ persona_3/    # Nueva
â”œâ”€â”€ persona_4/    # Nueva
â””â”€â”€ persona_N/    # Nueva
```

**RecomendaciÃ³n mÃ­nima**:
- Al menos 10-20 personas diferentes
- 5-10 fotos por persona en train
- 2-3 fotos por persona en val

---

### **OpciÃ³n 3: Usar otro dataset pÃºblico**

Otros datasets que puedes descargar manualmente:

| Dataset | Personas | ImÃ¡genes | TamaÃ±o | URL |
|---------|----------|----------|--------|-----|
| **LFW** | 5,749 | 13,233 | 173 MB | http://vis-www.cs.umass.edu/lfw/lfw.tgz |
| **CelebA** | 10,177 | 202,599 | 1.4 GB | https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html |
| **VGGFace2** | 9,131 | 3.31M | ~37 GB | http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/ |

---

### **OpciÃ³n 4: Continuar con el dataset actual**

Si solo quieres practicar el proceso, puedes:
- Mantener el dataset pequeÃ±o actual (2 personas)
- Experimentar con hiperparÃ¡metros
- Entender el flujo completo

**Nota**: El modelo tendrÃ¡ overfitting, pero es vÃ¡lido para aprendizaje.

---

## ğŸ“ PrÃ³ximos pasos

Una vez que tengas el dataset:

1. **Ajustar BATCH_SIZE** en `config.py`:
   - Para LFW completo: `BATCH_SIZE = 32`
   - Para dataset pequeÃ±o: mantener `BATCH_SIZE = 4`

2. **Entrenar**:
   ```bash
   source venv/bin/activate
   python3 train.py
   ```

3. **Validar**:
   ```bash
   python3 test.py --eval
   python3 test.py --verify foto1.jpg foto2.jpg
   ```

---

## ğŸ¯ Estado actual

âœ… **VersiÃ³n base funcional** guardada en git (commit f1d4966)  
âœ… **CÃ³digo completo** y probado  
â¸ï¸ **Esperando dataset** para entrenamiento a escala real  
